#!/usr/bin/env python

import argparse
import json
import logging
import os
import re
import subprocess as sp
import sys
import tempfile
import time
import xml.etree.ElementTree as ET
from typing import NamedTuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("project-coverage")


NUM_TESTS_RE = re.compile(r"collected\s+(\d+)\s+items")


class Result(NamedTuple):
    revision: str
    coverage: float
    time: float
    num_tests: int
    num_production_lines: int
    num_test_lines: int

    @classmethod
    def null(cls, revision, num_production_lines, num_test_lines):
        return cls(
            revision=revision,
            coverage=None,
            time=None,
            num_tests=None,
            num_production_lines=num_production_lines,
            num_test_lines=num_test_lines,
        )

    def to_dict(self):
        return {
            "revision": self.revision,
            "coverage": self.coverage,
            "time": self.time,
            "num_tests": self.num_tests,
            "num_production_lines": self.num_production_lines,
            "num_test_lines": self.num_test_lines,
        }


def checkout(revision):
    logger.debug(f"checking out {revision}")
    sp.check_call(["git", "checkout", "--quiet", revision])


def run_tests(temp_filename, parallel):
    logger.debug("running tests")
    cmd = ["pytest", "-x", "--cov-report", f"xml:{temp_filename}"]
    if parallel:
        cmd.extend(["-n", "auto"])
    sp.check_call(cmd)


def extract_coverage(coverage_io):
    cov_text = coverage_io.read().decode()
    root = ET.fromstring(cov_text)
    return float(root.attrib["line-rate"])


def get_current_rev():
    output = sp.check_output(["git", "rev-parse", "--abbrev-ref", "HEAD"])
    return output.decode().strip()


def extract_num_tests():
    output = sp.check_output(["pytest", "--collect-only"]).decode().split("\n")
    for line in output:
        match = NUM_TESTS_RE.match(line.strip())
        if match is not None:
            return int(match.group(1))


def extract_num_lines(path="."):
    output = sp.check_output(["tokei", path]).decode().split("\n")
    for line in output:
        if "Total" in line and "(Total)" not in line:
            parts = line.strip().split()
            assert parts[0] == "Total"
            assert len(parts) == 6
            return int(parts[3])


def reset_dir():
    sp.check_call(["git", "reset", "--quiet", "--hard"])


def calculate_revisions(merges_only):
    cmd = ["git", "rev-list", "--reverse"]
    if merges_only:
        cmd.append("--merges")
    cmd.append(f"{args.start}..{args.end}")

    cmd_output = sp.check_output(cmd).decode().split("\n")

    return [line.strip() for line in cmd_output if line]


def extract_test_lines():
    return extract_num_lines("tests")


def extract_production_lines():
    test_paths = ["src", "lambda_handler"]
    for path in test_paths:
        if os.path.isdir(path):
            return extract_num_lines(path)
    logger.warning("could not determine production code directory")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-s", "--start", required=True)
    parser.add_argument("-e", "--end", required=True)
    parser.add_argument(
        "-a",
        "--all",
        action="store_true",
        default=False,
        help="Include all commits, not just merges",
    )
    parser.add_argument(
        "-c", "--collect-only", action="store_true", default=False
    )  # noqa: E501
    parser.add_argument(
        "--parallel",
        action="store_true",
        default=False,
        help="Run pytest tests in parallel (using xdist)",
    )
    parser.add_argument("-v", "--verbose", action="store_true", default=False)
    parser.add_argument(
        "-o",
        "--output",
        required=False,
        default="-",
        type=argparse.FileType("w"),  # noqa: E501
    )
    args = parser.parse_args()

    if args.verbose:
        logger.setLevel(logging.DEBUG)

    current_rev = get_current_rev()
    logger.debug(f"current rev: {current_rev}")

    try:

        revs = calculate_revisions(not args.all) + [args.end]

        logging.info(f"collected {len(revs)} revs")

        if args.collect_only:
            sys.exit(0)

        coverages = []
        for rev in revs:
            checkout(rev)
            num_production_lines = extract_production_lines()
            num_test_lines = extract_test_lines()

            with tempfile.NamedTemporaryFile() as tfile:
                try:
                    num_tests = extract_num_tests()
                    start_time = time.time()
                    run_tests(tfile.name, parallel=args.parallel)
                except Exception:
                    logger.exception(
                        f"error running texts, skipping revision {rev}"
                    )  # noqa: E501
                    coverages.append(
                        Result.null(
                            revision=rev,
                            num_production_lines=num_production_lines,
                            num_test_lines=num_test_lines,
                        )
                    )  # noqa: E501
                    continue

                end_time = time.time()
                tfile.seek(0)
                coverage = extract_coverage(tfile)
                result = Result(
                    revision=rev,
                    coverage=coverage,
                    time=end_time - start_time,
                    num_tests=num_tests,
                    num_production_lines=num_production_lines,
                    num_test_lines=num_test_lines,
                )
                coverages.append(result)
            reset_dir()

        print(json.dumps([c.to_dict() for c in coverages]), file=args.output)

    finally:
        checkout(current_rev)
